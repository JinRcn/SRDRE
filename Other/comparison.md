## Comparative analysis

We present a comparative analysis between SRDRE and the widely used REDItools. Since REDItools is designed for bulk RNA-seq data, we adapted the spatial transcriptomics data to ensure a fair comparison. Our analysis was conducted as follows:
- **a) Data Preparation**: We used the mouse brain spatial transcriptomics dataset (available at https://www.10xgenomics.com/datasets/adult-mouse-brain-coronal-section-fresh-frozen-1-standard) as our test case. Spatial regions were segmented according to anatomical annotations, and reads from each distinct region were pooled to generate pseudo-bulk RNA-seq samples.
- **b) Ground Truth Definition**: To establish a set of high-confidence, known RNA editing sites for benchmarking, we leveraged the REDIportal dataset. We applied the REDItoolKnown.py module from REDItools to the pseudo-bulk samples to identify “true” editing sites present in each region.
- **c) De Novo Detection with REDItools**: We then executed the REDItoolDenovo.py module on the same pseudo-bulk samples to perform de novo discovery of RNA editing sites. This output represents the predictions generated by the established REDItools pipeline.
- **d) Detection with SRD-RE**: In parallel, we applied our SRD-RE method directly to the original spatial transcriptomics data to identify RNA editing sites.

## Performance Evaluation

- **e) F1 score**: For each spatial region (i.e., each pseudo-bulk sample), we considered the sites identified by REDItoolKnown.py as the ground truth. We then calculated the Precision, Recall, and F1-score for both the de novo REDItools predictions and the SRD-RE predictions (after mapping them to the corresponding regions). Our results demonstrate that SRD-RE achieves a better balance of sensitivity and specificity compared to REDItools when analyzing spatial data, as reflected by a higher overall F1-score.

<img width="720" height="432" alt="F1-score" src="https://github.com/user-attachments/assets/da61f5cf-7fe9-48e8-a99a-b53e9e797bb1" />


- **f) Runtime Performance**: The runtime results, now documented in the repository, highlight a significant advantage of our tool:
  
  Our Tool: ~7 hours<br>
  REDItools (REDItoolDenovo.py mode): ~30 hours

<img width="216" height="432" alt="time" src="https://github.com/user-attachments/assets/d5eed1cd-bf2f-44c8-85af-a22aaa4c11df" />

